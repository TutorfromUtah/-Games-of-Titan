{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input style = \"float:right\" type=\"submit\" value=\"Toggle code\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input style = \"float:right\" type=\"submit\" value=\"Toggle code\">''')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up visualisations\n",
    "sns.set_style(style='white') \n",
    "sns.set(rc={\n",
    "    'figure.figsize':(12,7), \n",
    "    'axes.facecolor': 'white',\n",
    "    'axes.grid': True, 'grid.color': '.9',\n",
    "    'axes.linewidth': 1.0,\n",
    "    'grid.linestyle': u'-'},font_scale=1.5)\n",
    "custom_colors = [\"#3498db\", \"#95a5a6\",\"#34495e\", \"#2ecc71\", \"#e74c3c\"]\n",
    "sns.set_palette(custom_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the data from the CSV file. We use a flag IS_FOR_KAGGLE to toggle the path of the data file.\n",
    "IS_FOR_KAGGLE = False\n",
    "\n",
    "if IS_FOR_KAGGLE:\n",
    "    trd = pd.read_csv('../input/train.csv')\n",
    "    tsd = pd.read_csv('../input/test.csv')\n",
    "else:\n",
    "    trd = pd.read_csv('train.csv')\n",
    "    tsd = pd.read_csv('test.csv')\n",
    "\n",
    "td = pd.concat([trd, tsd], ignore_index=True, sort  = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Getting the hang of the data\n",
    "The data contains 1309 rows and 12 colunmns. Each row signifies a human on the deck and each column is an attribute corresponding to that human."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1309, 12)\n",
    "On diving deeper in to the columns, we see five integer type columns, five object types (strings) and two columns with decimal values. Also, all the columns do not have 1309 values which indicates that there are missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Missing values\n",
    "The line plot and the heat map below show the number of missing values in all columns. There are multiple columns that have missing values\n",
    "\n",
    "Age\n",
    "Cabin\n",
    "Embarked\n",
    "Fare\n",
    "Survived\n",
    "77.5% of data is NOT available for the column 'Cabin'. Hence, it can be dropped in our analysis and prediction. An alternate approach would have been to predict values for the missing values. However, it is not recommended as the number of values available for Cabin is significantly lower.\n",
    "\n",
    "In contrast, Embarked has only 2 missing missing values. As the column contains 0.15% missing values, the values can be substituted by the mode of the column.\n",
    "\n",
    "The column 'Age' on the other hand has 177 missing values which contribute to 20% on the total expected values. We will impute the age data by categorising people on the basis of their title and finding the median age.\n",
    "\n",
    "Fare has one missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(td.isnull().sum()).plot.line().set_title(\"Number of missing values in the given features\")\n",
    "td.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PassengerId       0\n",
    "Survived        418\n",
    "Pclass            0\n",
    "Name              0\n",
    "Sex               0\n",
    "Age             263\n",
    "SibSp             0\n",
    "Parch             0\n",
    "Ticket            0\n",
    "Fare              1\n",
    "Cabin          1014\n",
    "Embarked          2\n",
    "dtype: int64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(td.isnull(), cbar = False).set_title(\"Missing values heatmap\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text(0.5, 1, 'Missing values heatmap')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Number of unique values\n",
    "To comprehend the categorical data in the training data, we list down al the columns with the number of unique values they have. We infer that\n",
    "\n",
    "survived and Sex can have two distinct values\n",
    "Embarked and PClass have three distinct values\n",
    "So, we have four columns of cateogrical data - Survived, Sex, Embarked and PClass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td.nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PassengerId    1309\n",
    "Survived          2\n",
    "Pclass            3\n",
    "Name           1307\n",
    "Sex               2\n",
    "Age              98\n",
    "SibSp             7\n",
    "Parch             8\n",
    "Ticket          929\n",
    "Fare            281\n",
    "Cabin           186\n",
    "Embarked          3\n",
    "dtype: int64"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features\n",
    "4. Survived\n",
    "The horizontal bar plot below shows the percentage of people that survived and percentage of people that unfortunately couldn't make it out alive from the disaster. More than 60% of the people on the ship died."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trd.Survived.value_counts(normalize=True) * 100).plot.barh().set_title(\"Training Data - Percentage of people su"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text(0.5, 1.0, 'Training Data - Percentage of people survived and Deceased')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Pclass\n",
    "Pclass or passenger class represents the traveling class of commuter. There were three classes. In the combined dataset, a clear majority (709) traveled in the third class, followed by the second (277) and then the first (323).\n",
    "\n",
    "The number of passengers in the third class was more than the number of passengers in first and second class combined.\n",
    "\n",
    "With the missing survived values, More than 40% of the first class passengers were rescued. The pattern differed for the second and third class survivors as roughly around 70% of the second class passengers lost their lives. The numbers skyrocketed for the third class passengers. More than 80% of the third class passengers couldn't survive the disaster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_pclass = trd.Pclass.value_counts().plot.pie().legend(labels=[\"Class 3\",\"Class 1\",\"Class 2\"], loc='center rig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclass_1_survivor_distribution = round((trd[trd.Pclass == 1].Survived == 1).value_counts()[1]/len(trd[trd.Pclass == 1]) * 100, 2)\n",
    "pclass_2_survivor_distribution = round((trd[trd.Pclass == 2].Survived == 1).value_counts()[1]/len(trd[trd.Pclass == 2]) * 100, 2)\n",
    "pclass_3_survivor_distribution = round((trd[trd.Pclass == 3].Survived == 1).value_counts()[1]/len(trd[trd.Pclass == 3]) * 100, 2)\n",
    "pclass_perc_df = pd.DataFrame(\n",
    "    { \"Percentage Survived\":{\"Class 1\": pclass_1_survivor_distribution,\"Class 2\": pclass_2_survivor_distribution, \"Class 3\": pclass_3_survivor_distribution},  \n",
    "     \"Percentage Not Survived\":{\"Class 1\": 100-pclass_1_survivor_distribution,\"Class 2\": 100-pclass_2_survivor_distribution, \"Class 3\": 100-pclass_3_survivor_distribution}})\n",
    "pclass_perc_df.plot.bar().set_title(\"Training Data - Percentage of people survived on the basis of class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text(0.5, 1.0, 'Training Data - Percentage of people survived on the basis of class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in [1,2,3]:    ## for 3 classes\n",
    "    trd.Age[trd.Pclass == x].plot(kind=\"kde\")\n",
    "plt.title(\"Age density in classes\")\n",
    "plt.legend((\"1st\",\"2nd\",\"3rd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in [\"male\",\"female\"]:\n",
    "    td.Pclass[td.Sex == x].plot(kind=\"kde\")\n",
    "plt.title(\"Training Data - Gender density in classes\")\n",
    "plt.legend((\"Male\",\"Female\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<matplotlib.legend.Legend at 0x119fd4898>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclass_perc_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\tPercentage Survived\tPercentage Not Survived\n",
    "Class 1\t62.96\t37.04\n",
    "Class 2\t47.28\t52.72\n",
    "Class 3\t24.24\t75.76"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Sex\n",
    "Roughly around 65% of the tourists were male while the remaining 35% were female. However, the percentage of female survivors was higher than the number of male survivors.\n",
    "\n",
    "More than 80% male passengers had to die as compared to around 70% female passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_sex = (trd.Sex.value_counts(normalize = True) * 100).plot.bar()\n",
    "male_pr = round((trd[trd.Sex == 'male'].Survived == 1).value_counts()[1]/len(trd.Sex) * 100, 2)\n",
    "female_pr = round((trd[trd.Sex == 'female'].Survived == 1).value_counts()[1]/len(trd.Sex) * 100, 2)\n",
    "sex_perc_df = pd.DataFrame(\n",
    "    { \"Percentage Survived\":{\"male\": male_pr,\"female\": female_pr},  \"Percentage Not Survived\":{\"male\": 100-male_pr,\"female\": 100-female_pr}})\n",
    "sex_perc_df.plot.barh().set_title(\"Percentage of male and female survived and Deceased\")\n",
    "fig_sex"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<matplotlib.axes._subplots.AxesSubplot at 0x1071acd30>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Age\n",
    "The description of column 'Age' tells us that the youngest traveler onboard was aged around 2 months and the oldest commuter was 80 years. The average age of passengers onboard was just under 30 years. However, it must be remembered that these observations are with missing values. Since we know that the oldest passenger was 80, we can plot age range and number of people survived or died for that age range.\n",
    "\n",
    "Apparently, higher number of children below age 10 were saved than died. For every other age group, the number of casualities was higher than the number of survivors. More than 140 people within the age group 20 and 30 were dead as compared to just around 80 people of the same age range sustained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(td.Age.describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Age\n",
    "count\t1046.000000\n",
    "mean\t29.881138\n",
    "std\t14.413493\n",
    "min\t0.170000\n",
    "25%\t21.000000\n",
    "50%\t28.000000\n",
    "75%\t39.000000\n",
    "max\t80.000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td['Age_Range'] = pd.cut(td.Age, [0, 10, 20, 30, 40, 50, 60,70,80])\n",
    "sns.countplot(x = \"Age_Range\", hue = \"Survived\", data = td, palette=[\"C1\", \"C0\"]).legend(labels = [\"Deceased\", \"Survived\"]\n",
    "                                                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(td['Age'].dropna(),color='darkgreen',bins=30)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. SibSp\n",
    "SibSp is the number of siblings or spouse of a person onboard. A maximum of 8 siblings and spouses traveled along with one of the tourists.\n",
    "\n",
    "More than 90% people traveled alone or with one of their sibling or spouse.\n",
    "\n",
    "The chances of survival dropped drastically if someone traveled with more than 2 siblings or spouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td.SibSp.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count    1309.000000\n",
    "mean        0.498854\n",
    "std         1.041658\n",
    "min         0.000000\n",
    "25%         0.000000\n",
    "50%         0.000000\n",
    "75%         1.000000\n",
    "max         8.000000\n",
    "Name: SibSp, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = pd.DataFrame()\n",
    "ss['survived'] = trd.Survived\n",
    "ss['sibling_spouse'] = pd.cut(trd.SibSp, [0, 1, 2, 3, 4, 5, 6,7,8], include_lowest = True)\n",
    "(ss.sibling_spouse.value_counts()).plot.area().set_title(\"Training Data - Number of siblings or spouses vs survival count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text(0.5, 1.0, 'Training Data - Number of siblings or spouses vs survival count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sns.countplot(x = \"sibling_spouse\", hue = \"survived\", data = ss, palette=[\"C1\", \"C0\"]).legend(labels = [\"Deceased\", \"Survived\"])\n",
    "x.set_title(\"Training Data - survival based on number of siblings or spouses\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Parch\n",
    "Similar to the SibSp, this feature contained the number of parents or children each passenger was traveling with. A maximum of 9 parents/children traveled along with one of the passenger.\n",
    "\n",
    "We will create two new columns, a column named family will have the sum of the number of siblings/spouse and number of parents/children.\n",
    "\n",
    "People traveling alone had higher chances of survival. So, we also create a column Is_Alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(td.Parch.describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parch\n",
    "count\t1309.000000\n",
    "mean\t0.385027\n",
    "std\t0.865560\n",
    "min\t0.000000\n",
    "25%\t0.000000\n",
    "50%\t0.000000\n",
    "75%\t0.000000\n",
    "max\t9.000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = pd.DataFrame()\n",
    "pc['survived'] = trd.Survived\n",
    "pc['parents_children'] = pd.cut(trd.Parch, [0, 1, 2, 3, 4, 5, 6], include_lowest = True)\n",
    "(pc.parents_children.value_counts()).plot.area().set_title(\"Training Data - Number of parents/children and survival density"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text(0.5, 1.0, 'Training Data - Number of parents/children and survival density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sns.countplot(x = \"parents_children\", hue = \"survived\", data = pc, palette=[\"C1\", \"C0\"]).legend(labels = [\"Deceased\", \"Survived\"])\n",
    "x.set_title(\"Training Data - Survival based on number of parents/children\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td['Family'] = td.Parch + td.SibSp\n",
    "td['Is_Alone'] = td.Family == 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Ticket\n",
    "As the feature 'Ticket' does not provide any additional information, we would not consider this feature\n",
    "\n",
    "11. Fare\n",
    "It is clear that there is a strong correlation between the fare and the survival. The higher a tourist paid, the higher would be his chances to survive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td.Fare.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count    1308.000000\n",
    "mean       33.295479\n",
    "std        51.758668\n",
    "min         0.000000\n",
    "25%         7.895800\n",
    "50%        14.454200\n",
    "75%        31.275000\n",
    "max       512.329200\n",
    "Name: Fare, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td['Fare_Category'] = pd.cut(td['Fare'], bins=[0,7.90,14.45,31.28,120], labels=['Low','Mid',\n",
    "                                                                                      'High_Mid','High'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sns.countplot(x = \"Fare_Category\", hue = \"Survived\", data = td, palette=[\"C1\", \"C0\"]).legend(labels = [\"Deceased\", \"Survived\"])\n",
    "x.set_title(\"Survival based on fare category\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Cabin\n",
    "As Cabin has a lot of missing values, we will impute it in following section and then use it for prediction.\n",
    "\n",
    "13. Embarked\n",
    "Embarked signifies where the traveler boarded from. There are three possible values for Embark - Southampton,Cherbourg,Queenstown.\n",
    "\n",
    "In combined data, more than 70% of the people boarded from Southampton. Just under 20% boarded from Cherbourg and the rest boarded from Queenstown.\n",
    "\n",
    "More People who boarded from Cherbourg survived than those who died"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sns.countplot(x = \"Embarked\", hue = \"Survived\", data = trd, palette=[\"C1\", \"C0\"])\n",
    "p.set_xticklabels([\"Southampton\",\"Cherbourg\",\"Queenstown\"])\n",
    "p.legend(labels = [\"Deceased\", \"Survived\"])\n",
    "p.set_title(\"Training Data - Survival based on embarking point.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text(0.5, 1.0, 'Training Data - Survival based on embarking point.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Imputation\n",
    "Embarked\n",
    "Since embarked only has two missing values and the highest number of people boarded the ship from Southampton, the probablity of boarding from Southampton is high. So, we fill the missing values with Southampton. However, instead of manually putting in Southampton, we would find the mode of the Embarked column and substitute missing values with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td.Embarked.fillna(td.Embarked.mode()[0], inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age\n",
    "Age has 263 missing values. To deal with missing values, we first try to categorise the people with their titles. There are 17 different titles in the training data. We group the titles and sex and then we find the median of all the categories and replace the missing values with the median of that category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td['Salutation'] = td.Name.apply(lambda name: name.split(',')[1].split('.')[0].strip()) \n",
    "td.Salutation.nunique()\n",
    "wc = WordCloud(width = 1000,height = 450,background_color = 'white').generate(str(td.Salutation.values))\n",
    "plt.imshow(wc, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()\n",
    "\n",
    "td.Salutation.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mr              757\n",
    "Miss            260\n",
    "Mrs             197\n",
    "Master           61\n",
    "Rev               8\n",
    "Dr                8\n",
    "Col               4\n",
    "Ms                2\n",
    "Mlle              2\n",
    "Major             2\n",
    "Dona              1\n",
    "Don               1\n",
    "Jonkheer          1\n",
    "Sir               1\n",
    "the Countess      1\n",
    "Capt              1\n",
    "Mme               1\n",
    "Lady              1\n",
    "Name: Salutation, dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = td.groupby(['Sex', 'Pclass'])  \n",
    "td.Age = grp.Age.apply(lambda x: x.fillna(x.median()))\n",
    "\n",
    "#If still any row remains\n",
    "td.Age.fillna(td.Age.median, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_df = pd.DataFrame({\n",
    "    \"Survived\":\n",
    "    td[td.Survived == 1].Salutation.value_counts(),\n",
    "    \"Total\":\n",
    "        td.Salutation.value_counts()\n",
    "})\n",
    "s = sal_df.plot.barh()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cabin\n",
    "Assigning NA for non available cabin values. Pulling deck value from Cabin and adding a feature 'Deck'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td.Cabin = td.Cabin.fillna('NA')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding & dropping columns\n",
    "Using Pandas' get dummies we encoded the categorical data. Later, we drop all the columns we encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = pd.concat([td,pd.get_dummies(td.Cabin, prefix=\"Cabin\"),pd.get_dummies(td.Age_Range, prefix=\"Age_Range\"), pd.get_dummies(td.Embarked, prefix=\"Emb\", drop_first = True), pd.get_dummies(td.Salutation, prefix=\"Title\", drop_first = True),pd.get_dummies(td.Fare_Category, prefix=\"Fare\", drop_first = True), pd.get_dummies(td.Pclass, prefix=\"Class\", drop_first = True)], axis=1)\n",
    "td['Sex'] = LabelEncoder().fit_transform(td['Sex'])\n",
    "td['Is_Alone'] = LabelEncoder().fit_transform(td['Is_Alone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td.drop(['Pclass', 'Fare','Cabin', 'Fare_Category','Name','Salutation', 'Ticket','Embarked', 'Age_Range', 'Sibling'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction\n",
    "Prediction algorithms used:\n",
    "\n",
    "Gaussian Naive Bayes\n",
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to be predicted\n",
    "X_to_be_predicted = td[td.Survived.isnull()]\n",
    "X_to_be_predicted = X_to_be_predicted.drop(['Survived'], axis = 1)\n",
    "\n",
    "#Training data\n",
    "train_data = td\n",
    "train_data = train_data.dropna()\n",
    "feature_train = train_data['Survived']\n",
    "label_train  = train_data.drop(['Survived'], axis = 1)\n",
    "train_data.shape #891 x 28\n",
    "\n",
    "##Gaussian\n",
    "clf = GaussianNB()\n",
    "x_train, x_test, y_train, y_test = train_test_split(label_train, feature_train, test_size=0.2)\n",
    "clf.fit(x_train,  np.ravel(y_train))\n",
    "print(\"NB Accuracy: \"+repr(round(clf.score(x_test, y_test) * 100, 2)) + \"%\")\n",
    "result_rf=cross_val_score(clf,x_train,y_train,cv=10,scoring='accuracy')\n",
    "print('The cross validated score for GNB is:',round(result_rf.mean()*100,2))\n",
    "y_pred = cross_val_predict(clf,x_train,y_train,cv=10)\n",
    "sns.heatmap(confusion_matrix(y_train,y_pred),annot=True,fmt='3.0f',cmap=\"summer\")\n",
    "plt.title('Confusion_matrix for NB', y=1.05, size=15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB Accuracy: 61.45%\n",
    "The cross validated score for GNB is: 64.61\n",
    "Text(0.5, 1.05, 'Confusion_matrix for NB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Random forest\n",
    "clf = RandomForestClassifier(criterion='entropy', \n",
    "                             n_estimators=700,\n",
    "                             min_samples_split=10,\n",
    "                             min_samples_leaf=1,\n",
    "                             max_features='auto',\n",
    "                             oob_score=True,\n",
    "                             random_state=1,\n",
    "                             n_jobs=-1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(label_train, feature_train, test_size=0.2)\n",
    "clf.fit(x_train,  np.ravel(y_train))\n",
    "print(\"RF Accuracy: \"+repr(round(clf.score(x_test, y_test) * 100, 2)) + \"%\")\n",
    "\n",
    "result_rf=cross_val_score(clf,x_train,y_train,cv=10,scoring='accuracy')\n",
    "print('The cross validated score for Random forest is:',round(result_rf.mean()*100,2))\n",
    "y_pred = cross_val_predict(clf,x_train,y_train,cv=10)\n",
    "sns.heatmap(confusion_matrix(y_train,y_pred),annot=True,fmt='3.0f',cmap=\"summer\")\n",
    "plt.title('Confusion_matrix for RF', y=1.05, size=15)\n",
    "RF Accuracy: 89.39%\n",
    "The cross validated score for Random forest is: 80.94\n",
    "result = clf.predict(X_to_be_predicted)\n",
    "submission = pd.DataFrame({'PassengerId':X_to_be_predicted.PassengerId,'Survived':result})\n",
    "submission.Survived = submission.Survived.astype(int)\n",
    "print(submission.shape)\n",
    "filename = 'Titanic Predictions.csv'\n",
    "submission.to_csv(filename,index=False)\n",
    "print('Saved file: ' + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b8c24ec10757e178d54ea5b1a4eb759bc1e256e8fa0a864056fea571ee30453"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
